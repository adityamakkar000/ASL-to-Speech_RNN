# ASL-to-Speech_RNN

We aim to use a time series RNN to model gesture control. We take in 10 flex resistor inputs, and train the model, and then use it to predict the upcoming gesture. 


# Gloves

The gloves use an arudino mega and 10 flex sensors to linearly map 0 to 5v --> 0 to 1023

![](https://github.com/blueishfiend692/ASL-to-Speech_RNN/blob/master/gloves.jpg)



# Machine learning
Using an RNN with a classified dataset of 20 x 10 labelled words, we are able to achive an accuracy of 84%. 

![](https://github.com/blueishfiend692/ASL-to-Speech_RNN/blob/master/ML.jpg)





Here is a link to the youtube demo --> https://www.youtube.com/watch?v=hv4gWkpeqSk 
